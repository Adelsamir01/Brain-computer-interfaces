{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12-Class SSVEP Dataset\n",
    "## Classification Using Canonical Correaltion Analysis (CCA)\n",
    "### The following is implemented on a 12-Class publicly available SSVEP EEG Dataset\n",
    "\n",
    "<img src=\"12_classSSVEP.png\">\n",
    "\n",
    "#### Dataset URL: \n",
    "https://github.com/mnakanishi/12JFPM_SSVEP/tree/master/data\n",
    "\n",
    "#### Dataset Paper:\n",
    "Masaki Nakanishi, Yijun Wang, Yu-Te Wang and Tzyy-Ping Jung, \n",
    "\"A Comparison Study of Canonical Correlation Analysis Based Methods for Detecting Steady-State Visual Evoked Potentials,\" \n",
    "PLoS One, vol.10, no.10, e140703, 2015. \n",
    "\n",
    "#### Implementation:\n",
    "Note: Following implementation is an asynchronous SSVEP BCI using CCA classification for 1 second data length\n",
    "\n",
    "Aravind Ravi | eBionics Lab | University of Waterloo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "from scipy.signal import butter, lfilter, filtfilt\n",
    "from scipy.signal import freqz\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### buffer() - Function to segment the data based on fixed window lengths and overlap (Windowing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer(data,duration,dataOverlap):\n",
    "    numberOfSegments = int(math.ceil((len(data)-dataOverlap)/(duration-dataOverlap)))\n",
    "    #print(data.shape)\n",
    "    tempBuf = [data[i:i+duration] for i in range(0,len(data),(duration-int(dataOverlap)))]\n",
    "    tempBuf[numberOfSegments-1] = np.pad(tempBuf[numberOfSegments-1],(0,duration-tempBuf[numberOfSegments-1].shape[0]),'constant')\n",
    "    tempBuf2 = np.vstack(tempBuf[0:numberOfSegments])\n",
    "    return tempBuf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### butterBandpass () - Function generates the filter coefficients\n",
    "#### butterBandpassFilter () - Function performs filtering on the input data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butterBandpass(lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butterBandpassFilter(data, lowcut, highcut, fs, order=4):\n",
    "    b, a = butterBandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canonical Correlation Analysis (CCA)\n",
    "$$\\DeclareMathOperator*{\\argmax}{argmax}$$\n",
    "\n",
    "Consider two multidimensional variables $X$, $Y$ where $X$ refers to the set of multi-channel EEG data and $Y$ refers to the set of reference signals of the same length as $X$. The linear combinations of $X$ and $Y$ are given as $x = X'W_{x}$ and $y = Y'W_{y}$. CCA finds the weights, $W_{x}$ and $W_{y}$ that maximize the correlation between $x$ and $y$ by solving (1). The maximum of $\\rho$ with respect to $W_{x}$ and $W_{y}$ is the maximum correlation.\n",
    "\n",
    "$$\\max_{W_{x},W_{y}} \\rho(x,y) = \\frac{\\mathbb{E}{[W_{x}'XY'W_{y}]}}{\\sqrt{\\mathbb{E}{[W_{x}'XX'W_{x}]}\\mathbb{E}{[W_{y}'YY'W_{y}]}}}$$\n",
    "\n",
    "The reference signals $Y_{n}$  are defined as:\n",
    "\n",
    "$$Y_{n} = \\begin{bmatrix} \\sin({2 \\pi f_{n}t}) \\\\ \\cos({2 \\pi f_{n}t}) \\\\ \\vdots \\\\ \\sin({4 \\pi  f_{n}t}) \\\\ \\cos({4 \\pi  f_{n}t}) \\end{bmatrix},t = \\begin{bmatrix} \n",
    "    \\frac{1}{f_{s}}\n",
    "    \\frac{2}{f_{s}}\n",
    "    \\dots\n",
    "    \\frac{N_{s}}{f_{s}}\n",
    "    \\end{bmatrix}$$\n",
    "    \n",
    "where $Y_{n} \\in \\mathbb{R}^{2 N_{h} \\times N_{s}} $, $f_{n}$ is the stimulation frequency, $f_{s}$ is the sampling frequency, $N_{s}$ is number of samples, and $N_{h}$ is the number of harmonics. Here, $N_{h}=2$. The canonical correlation features $\\rho_{f_{i}}$, where $i = 1,2,...,7$ are extracted for each segment of the EEG data, and the output class $C$ for a given sample can be determined as: $C = \\argmax (\\rho_{f_{i}})$\n",
    "\n",
    "#### getReferenceSignals () - Function generates sinusoidal reference templates for CCA for the first and second harmonics\n",
    "#### findCorr () - Function performs CCA on input EEG and set of reference sinusoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReferenceSignals(length, target_freq,samplingRate):\n",
    "    \n",
    "    reference_signals = []\n",
    "    t = np.arange(0, (length/(samplingRate)), step=1.0/(samplingRate))\n",
    "    #First harmonics/Fundamental freqeuncy\n",
    "    reference_signals.append(np.sin(np.pi*2*target_freq*t))\n",
    "    reference_signals.append(np.cos(np.pi*2*target_freq*t))\n",
    "    #Second harmonics\n",
    "    reference_signals.append(np.sin(np.pi*4*target_freq*t))\n",
    "    reference_signals.append(np.cos(np.pi*4*target_freq*t))\n",
    "    reference_signals = np.array(reference_signals)\n",
    "    return reference_signals\n",
    "\n",
    "def findCorr(n_components,numpy_buffer,freq):\n",
    "    # Perform Canonical correlation analysis (CCA)\n",
    "    # numpy_buffer - consists of the EEG\n",
    "    # freq - set of sinusoidal reference templates corresponding to the flicker frequency\n",
    "    cca = CCA(n_components)\n",
    "    corr=np.zeros(n_components)\n",
    "    result=np.zeros(freq.shape[0])\n",
    "    for freq_idx in range(0,freq.shape[0]):\n",
    "        cca.fit(numpy_buffer.T,np.squeeze(freq[freq_idx,:,:]).T)\n",
    "        O1_a,O1_b = cca.transform(numpy_buffer.T, np.squeeze(freq[freq_idx,:,:]).T)\n",
    "        ind_val=0\n",
    "        for ind_val in range(0,n_components):\n",
    "            corr[ind_val] = np.corrcoef(O1_a[:,ind_val],O1_b[:,ind_val])[0,1]\n",
    "            result[freq_idx] = np.max(corr)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 1  - Accuracy: 28.333333333333332 %\n",
      "Subject: 2  - Accuracy: 26.666666666666668 %\n",
      "Subject: 3  - Accuracy: 61.25000000000001 %\n",
      "Subject: 4  - Accuracy: 79.58333333333333 %\n",
      "Subject: 5  - Accuracy: 42.916666666666664 %\n",
      "Subject: 6  - Accuracy: 86.25 %\n",
      "Subject: 7  - Accuracy: 66.38888888888889 %\n",
      "Subject: 8  - Accuracy: 95.83333333333334 %\n",
      "Subject: 9  - Accuracy: 67.77777777777779 %\n",
      "Subject: 10  - Accuracy: 65.27777777777779 %\n",
      "Overall Accuracy Across Subjects: 62.02777777777777 % std: 22.027112221975585 %\n"
     ]
    }
   ],
   "source": [
    "#Variable to store all accuracies\n",
    "all_acc=np.zeros((10,1))\n",
    "\n",
    "#Iterate through all 10 subjects \n",
    "for sub in range(0,10):\n",
    "\n",
    "#Load the EEG Dataset\n",
    "    dataset=sio.loadmat('s'+str(sub+1)+'.mat')\n",
    "   \n",
    "    eeg=np.array(dataset['eeg'],dtype='float32')\n",
    "\n",
    "#Reading the required parameters\n",
    "#Number of classes\t\n",
    "    num_classes=eeg.shape[0]\n",
    "#Number of EEG channels\n",
    "    num_chan=eeg.shape[1]\n",
    "#Trial length of EEG\n",
    "    trial_len=eeg.shape[2]\n",
    "#Total number of trials\n",
    "    num_trials=eeg.shape[3]\n",
    "    sample_rate = 256\n",
    "#SSVEP flicker frequencies used for the 12 SSVEP targets   \n",
    "    flick_freq=np.array([9.25,11.25,13.25,9.75,11.75,13.75,10.25,12.25,14.25,10.75,12.75,14.75])\n",
    "#variable to store the true labels    \n",
    "    labels=[]\n",
    "    filtered_data = np.zeros(eeg.shape)\n",
    "#Iterate through the channels and trials for filtering the data using Bandpass filter between 6 Hz and 80 Hz\n",
    "    for cl in range(0,num_classes):\n",
    "        for ch in range(0,num_chan):\n",
    "            for tr in range(0,num_trials):\n",
    "                filtered_data[cl,ch,:,tr] = butterBandpassFilter(eeg[cl,ch,:,tr],6,80,sample_rate,order=4)\n",
    "\n",
    "#Extract the actual trial from the data (refer the paper for more details)\n",
    "    filtered_data = filtered_data[:,:,int(38+0.135*sample_rate):int(38+0.135*sample_rate+4*sample_rate-1),:]\n",
    "    eeg=[]\n",
    "#Segment the EEG trials into 1 second non-overlapping segments \n",
    "#Window/segment length in seconds\n",
    "    window_len=1\n",
    "#Shift of the window in seconds (indirectly specifies overlap)\n",
    "    shift_len=1\n",
    "\n",
    "#Converting into units of samples\n",
    "    duration=int(window_len*sample_rate)\n",
    "    data_overlap = (window_len-shift_len)*sample_rate\n",
    "    \n",
    "    numberOfSegments = int(math.ceil((filtered_data.shape[2]-data_overlap)/(duration-data_overlap)))\n",
    "    \n",
    "    segmented_data = np.zeros((filtered_data.shape[0],filtered_data.shape[1],numberOfSegments,duration,filtered_data.shape[3]))\n",
    "\n",
    "#Performing data segmentation on each trial and each channel for all classes of data\n",
    "    for cl in range(0,num_classes):\n",
    "        for ch in range(0,num_chan):\n",
    "            for tr in range(0,num_trials):\n",
    "                segmented_data[cl,ch,:,:,tr]=buffer(filtered_data[cl,ch,:,tr],duration,data_overlap)\n",
    "    \n",
    "    filtered_data=[]\n",
    "    freq_ref=[]\n",
    "#Generating the required sinusoidal templates for the given 12-class SSVEP classification\n",
    "    for fr in range(0,len(flick_freq)):\n",
    "        freq_ref.append(getReferenceSignals(duration,flick_freq[fr],sample_rate))\n",
    "    \n",
    "    freq_ref=np.array(freq_ref,dtype='float32')\n",
    "    \n",
    "    predicted_class=[]\n",
    "#Performing segment wise classification using CCA \n",
    "    for cl in range(0,num_classes):\n",
    "        for tr in range(0,num_trials):\n",
    "            for sg in range(0,numberOfSegments):\n",
    "#True labels are created here\n",
    "                labels.append(cl)\n",
    "#Perform CCA on a single segment\n",
    "                result=findCorr(1,segmented_data[cl,:,sg,:,tr],freqRef)\n",
    "#Pick the class that corresponds to the maximum canonical correlation coefficient\n",
    "                predicted_class.append(np.argmax(result)+1)\n",
    "    \n",
    "    segmented_data=[]\n",
    "    labels=np.array(labels)+1\n",
    "    predicted_class=np.array(predicted_class)\n",
    "#creating a confusion matrix of true versus predicted classification labels\n",
    "    c_mat = confusion_matrix(labels, predicted_class)\n",
    "#computing the accuracy from the confusion matrix\n",
    "    accuracy=np.divide(np.trace(c_mat),np.sum(np.sum(c_mat)))\n",
    "    all_acc[sub] = accuracy\n",
    "    print(\"Subject:\",sub+1, \" - Accuracy:\",accuracy*100,\"%\")\n",
    "#Mean overall accuracy across all subjects\n",
    "print(\"Overall Accuracy Across Subjects:\",np.mean(all_acc)*100,\"%\",\"std:\",np.std(all_acc)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "783px",
    "left": "1528px",
    "right": "20px",
    "top": "115px",
    "width": "387px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
